{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0cbe0df",
   "metadata": {},
   "source": [
    "## Problem set 4\n",
    "\n",
    "## Name: [TODO]\n",
    "\n",
    "## Link to your PS4 github repo: [TODO]\n",
    "\n",
    "### Problem 0 \n",
    "\n",
    "-2 points for every missing green OK sign. \n",
    "\n",
    "Make sure you are in the DATA1030 environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5d81ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from packaging.version import parse as Version\n",
    "from platform import python_version\n",
    "\n",
    "OK = '\\x1b[42m[ OK ]\\x1b[0m'\n",
    "FAIL = \"\\x1b[41m[FAIL]\\x1b[0m\"\n",
    "\n",
    "try:\n",
    "    import importlib\n",
    "except ImportError:\n",
    "    print(FAIL, \"Python version 3.12.10 is required,\"\n",
    "                \" but %s is installed.\" % sys.version)\n",
    "\n",
    "def import_version(pkg, min_ver, fail_msg=\"\"):\n",
    "    mod = None\n",
    "    try:\n",
    "        mod = importlib.import_module(pkg)\n",
    "        if pkg in {'PIL'}:\n",
    "            ver = mod.VERSION\n",
    "        else:\n",
    "            ver = mod.__version__\n",
    "        if Version(ver) == Version(min_ver):\n",
    "            print(OK, \"%s version %s is installed.\"\n",
    "                  % (lib, min_ver))\n",
    "        else:\n",
    "            print(FAIL, \"%s version %s is required, but %s installed.\"\n",
    "                  % (lib, min_ver, ver))    \n",
    "    except ImportError:\n",
    "        print(FAIL, '%s not installed. %s' % (pkg, fail_msg))\n",
    "    return mod\n",
    "\n",
    "\n",
    "# first check the python version\n",
    "pyversion = Version(python_version())\n",
    "\n",
    "if pyversion >= Version(\"3.12.10\"):\n",
    "    print(OK, \"Python version is %s\" % pyversion)\n",
    "elif pyversion < Version(\"3.12.10\"):\n",
    "    print(FAIL, \"Python version 3.12.10 is required,\"\n",
    "                \" but %s is installed.\" % pyversion)\n",
    "else:\n",
    "    print(FAIL, \"Unknown Python version: %s\" % pyversion)\n",
    "\n",
    "    \n",
    "print()\n",
    "requirements = {'numpy': \"2.2.5\", 'matplotlib': \"3.10.1\",'sklearn': \"1.6.1\", \n",
    "                'pandas': \"2.2.3\",'xgboost': \"3.0.0\", 'shap': \"0.47.2\", \n",
    "                'polars': \"1.27.1\", 'seaborn': \"0.13.2\"}\n",
    "\n",
    "# now the dependencies\n",
    "for lib, required_version in list(requirements.items()):\n",
    "    import_version(lib, required_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be46bb3",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "We will work with the recidivism dataset in the problem set. The dataset contains information on criminal offenders screened in Florida from 2013 to 2014. The target variable (`two_year_recid`) for this dataset indicates whether or not an individual committed another crime after being released from prision. The csv file and a description are available in the `data` folder.\n",
    "\n",
    "You can read more about the topic [here](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing) and [here](https://arxiv.org/pdf/2106.05498.pdf). We will work with this dataset again in the context of algorithmic bias towards the end of the term.\n",
    "\n",
    "You will read in the dataset, prepare the feature matrix and the target variable, perform EDA, and split the dataset into 60% training, 20% validation, and 20% test sets. Follow the steps outlined below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5012043-6e3c-4f0b-9c1c-49124445ac79",
   "metadata": {},
   "source": [
    "### Problem 1a (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1969dbb6-4f2c-4fd0-b540-8e2bd999c2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# import the necessary packages. feel free to use pandas or polars, matplotlib, and sklearn\n",
    "\n",
    "# read in the dataset\n",
    "\n",
    "# drop the id and name columns because those are not useful for a machine learning algorithm\n",
    "\n",
    "# prepare the feature matrix X\n",
    "\n",
    "# prepare the target variable y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e41aa75-98d3-484a-a645-67d42d702c0d",
   "metadata": {},
   "source": [
    "### Problem 1b (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2400de5-7161-409f-9a6c-4eff5b558ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# copy-paste the PS3 1a Q0-4 EDA questions here (modify as needed) and answer them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5920563-94b4-4e7d-926f-d4273c8f2151",
   "metadata": {},
   "source": [
    "### Problem 1c (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcd05ac-b22d-4132-902b-fc88def0e0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# visualize each feature (12 figures total)\n",
    "# make sure to add axis labels, add units if necessary, and add a figure title as well.\n",
    "\n",
    "# use sklearn to split the dataset into 60% training, 20% validation, and 20% test sets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89429e93-348b-4638-976f-6c2113e62345",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "You will preprocess the dataset in this problem. \n",
    "\n",
    "- First, you need to decide based on the dataset description, which features are continuous, ordinal, and categorical.\n",
    "- Then you will write functions that perform fit-transform on the training set. The functions you create are tested with sklearn. The ability to implement algorithms is a strong indicator that you understand them and it is a crucial step in learning.\n",
    "- Finally, you'll transform the validation and test sets using sklearn.\n",
    "\n",
    "Follow the steps outined below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37f1fdf-3968-44f1-8721-86684e399acf",
   "metadata": {},
   "source": [
    "### Problem 2a (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5363b33d-fc42-46a8-8294-c3ae0d4352e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necesasry packages\n",
    "\n",
    "# complete these lists. each feature name must appear exactly once in one of these lists\n",
    "continuous_ftrs = []\n",
    "ordinal_ftrs = [] \n",
    "# for ordinal features, describe the ordered list of categories\n",
    "ordinal_cats = []\n",
    "categorical_ftrs = []\n",
    "\n",
    "\n",
    "def standard_scaler(df,continuous_ftrs):\n",
    "    '''\n",
    "    TODO: the string between triple quotes is called the docstring of a function.\n",
    "    you saw examples of this in PS3 already.\n",
    "    now it is your task to write the docstring!\n",
    "    what does this function do?\n",
    "    what are the input parameters?\n",
    "    what are the outputs?\n",
    "    show in an example how to use the function.\n",
    "    Follow the docstring structure in PS3.\n",
    "    '''\n",
    "    # as in the previous problem set, test the input(s) to the function\n",
    "\n",
    "    # implement the standard scaler and transform the input\n",
    "    # you can use numpy, pandas or polars. do not use sklearn inside the function!\n",
    "\n",
    "    return df_scaled\n",
    "\n",
    "\n",
    "# test the standard scaler output. call the sklearn standard scaler.\n",
    "# check if the sklearn output and your output are identical\n",
    "# if not, raise a ValueError and debug your code.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89891cfc-3438-4218-85e4-24cedb8cfe3c",
   "metadata": {},
   "source": [
    "### Problem 2b (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ea75af-883d-4531-9caf-ec684c35a6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_encoder(df,categorical_ftrs):\n",
    "    '''\n",
    "    TODO: write the docstring of the function.\n",
    "    Follow the docstring structure in PS3.\n",
    "\n",
    "    '''\n",
    "    # test the input(s)\n",
    "\n",
    "    # implement the algorithm and transform the input\n",
    "    # you can use numpy, pandas or polars. do not use sklearn inside the function!\n",
    "\n",
    "\n",
    "    return df_onehot\n",
    "\n",
    "# test the one-hot encoder output. call the sklearn OHE.\n",
    "# check if the sklearn output and your output are identical\n",
    "# if not, raise a ValueError and debug your code.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d409a1-e311-4bb3-afdb-7ea41ca48e7d",
   "metadata": {},
   "source": [
    "### Problem 2c (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51fb21f-d19b-4a5c-9a14-a8109960aa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordinal_encoder(df, ordinal_ftrs, ordinal_cats):\n",
    "    '''\n",
    "    TODO: write the docstring of the function.\n",
    "    Follow the docstring structure in PS3.\n",
    "    Why do we need the ordinal_ftrs and ordinal_cats as inputs?\n",
    "\n",
    "    '''\n",
    "    # test the input(s)\n",
    "\n",
    "    # implement the algorithm and transform the input\n",
    "    # you can use numpy, pandas or polars. do not use sklearn inside the function!\n",
    "\n",
    "    \n",
    "    return df_ordinal\n",
    "\n",
    "# test the ordinal encoder output. call the sklearn OE.\n",
    "# check if the sklearn output and your output are identical\n",
    "# if not, raise a ValueError and debug your code.\n",
    "\n",
    "\n",
    "\n",
    "# now, please combine your three functions to create a df that is fully transformed\n",
    "# test this\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4dfa74-ca17-4db0-b574-e87f732a4e05",
   "metadata": {},
   "source": [
    "### Problem 2d (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d1102b-c2f2-463a-873b-b678aa95ffc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 1: use the sklearn transformers you prepared to test your functions and transform the validation and test sets.\n",
    "# make sure that the transformed train/val/test you prepared are identical to the sklearn transformed sets\n",
    "# if the sets are not identical, carefully read the manuals of all functions and methods that you use.\n",
    "\n",
    "# test 2: print out the headers of the fully transformed train, validation, and test sets\n",
    "\n",
    "# test 3: make sure that the order of the features is exactly the same in each set\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
